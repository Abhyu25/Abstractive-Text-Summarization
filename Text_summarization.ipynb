{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Text_summarization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEq-oYpmSM5r"
      },
      "source": [
        "# Text Summerization - Encoder Decoder with Attention Mechanism"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iFfGxm4XgZl"
      },
      "source": [
        "### Importing Basic libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "lisXNzYrYOoR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fff449d-0810-4b5e-b76c-eaaeeb46d913"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import contractions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uEL8_WrZ7-j",
        "outputId": "14c1ed9f-8600-467e-a560-a12a5448d257"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj3lfncbgBoK"
      },
      "source": [
        "!cp /content/drive/MyDrive/Data/news_summary.csv /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSr24NviXqio"
      },
      "source": [
        "### Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdnrzMpkYOoY"
      },
      "source": [
        "data_path = '/content/news_summary.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "z3NFHA0CYOoZ",
        "outputId": "dfc12854-083e-489f-f9a8-0f033bf8fb25"
      },
      "source": [
        "data = pd.read_csv(data_path)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headlines</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
              "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
              "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
              "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
              "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
              "      <td>Speaking about the sexual harassment allegatio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           headlines                                               text\n",
              "0  upGrad learner switches to career in ML & Al w...  Saurav Kant, an alumnus of upGrad and IIIT-B's...\n",
              "1  Delhi techie wins free food from Swiggy for on...  Kunal Shah's credit card bill payment platform...\n",
              "2  New Zealand end Rohit Sharma-led India's 12-ma...  New Zealand defeated India by 8 wickets in the...\n",
              "3  Aegon life iTerm insurance plan helps customer...  With Aegon Life iTerm Insurance plan, customer...\n",
              "4  Have known Hirani for yrs, what if MeToo claim...  Speaking about the sexual harassment allegatio..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV8b6w9YYOoa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91d4179e-0c5b-4bac-ddc5-726f8ece8281"
      },
      "source": [
        "stop_words = stopwords.words('english')\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = text.split()\n",
        "    for i in range(len(text)):\n",
        "        word = text[i]\n",
        "        text[i] = contractions.fix(word)\n",
        "    text = \" \".join(text)\n",
        "    text = text.split()\n",
        "    newtext = []\n",
        "    for word in text:\n",
        "        if word not in stop_words:\n",
        "            newtext.append(word)\n",
        "    text = \" \".join(newtext)\n",
        "    text = text.replace(\"'s\",'')\n",
        "    text = re.sub(r'\\(.*\\)','',text)\n",
        "    text = re.sub(r'[^a-zA-Z0-9. ]',' ',text)\n",
        "    text = re.sub(r'\\.','. ',text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text\n",
        "\n",
        "sample = '''Hello! This is our 'EE626' (PRML) course project. We've tried implementing a simple \"encoder-decoder\" model'''\n",
        "print(preprocess(sample))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello ee626 course project. tried implementing simple encoder decoder model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewSx5cepYOob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a06af4c-6481-4361-b408-d631c78c5fd1"
      },
      "source": [
        "data['headlines'] = data['headlines'].apply(lambda x:preprocess(x))\n",
        "data['text'] = data['text'].apply(lambda x:preprocess(x))\n",
        "\n",
        "print(data['headlines'][0], data['text'][0], sep='\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "upgrad learner switches career ml al 90 salary hike\n",
            "saurav kant alumnus upgrad iiit b pg program machine learning artificial intelligence sr systems engineer infosys almost 5 years work experience. program upgrad 360 degree career support helped transition data scientist tech mahindra 90 salary hike. upgrad online power learning powered 3 lakh careers. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxORJdThYOob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62907398-9ba9-4679-9c4b-7df2326c2f47"
      },
      "source": [
        "x = data['text']\n",
        "y = data['headlines']\n",
        "for i in range(20):\n",
        "    print(f'Summary: {y[i]}',f'Text:    {x[i]}', sep='\\n')\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Summary: upgrad learner switches career ml al 90 salary hike\n",
            "Text:    saurav kant alumnus upgrad iiit b pg program machine learning artificial intelligence sr systems engineer infosys almost 5 years work experience. program upgrad 360 degree career support helped transition data scientist tech mahindra 90 salary hike. upgrad online power learning powered 3 lakh careers. \n",
            "\n",
            "Summary: delhi techie wins free food swiggy one year cred\n",
            "Text:    kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year. pranav kaushik delhi techie bagged reward spending 2000 cred coins. users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult. fit more. \n",
            "\n",
            "Summary: new zealand end rohit sharma led india 12 match winning streak\n",
            "Text:    new zealand defeated india 8 wickets fourth odi hamilton thursday win first match five match odi series. india lost international match rohit sharma captaincy 12 consecutive victories dating back march 2018. match witnessed india getting 92 seventh lowest total odi cricket history. \n",
            "\n",
            "Summary: aegon life iterm insurance plan helps customers save tax\n",
            "Text:    aegon life iterm insurance plan customers enjoy tax benefits premiums paid save 46 800 taxes. plan provides life cover age 100 years. also customers options insure critical illnesses disability accidental death benefit rider life cover age 80 years. \n",
            "\n",
            "Summary: known hirani yrs metoo claims true sonam\n",
            "Text:    speaking sexual harassment allegations rajkumar hirani sonam kapoor said I known hirani many years. . . what true metoo movement get derailed. in metoo movement always believe woman. case need reserve judgment added. hirani accused assistant worked anju . \n",
            "\n",
            "Summary: rahat fateh ali khan denies getting notice smuggling currency\n",
            "Text:    pakistani singer rahat fateh ali khan denied receiving notice enforcement directorate allegedly smuggling foreign currency india. it would better authorities would served notice first publicised this reads press release issued behalf rahat. statement called allegation bizarre . \n",
            "\n",
            "Summary: india get 92 lowest odi total new zealand\n",
            "Text:    india recorded lowest odi total new zealand getting 92 runs 30. 5 overs fourth odi hamilton thursday. seven india batsmen dismissed single digit scores number ten batsman yuzvendra chahal top scored 18 . india previous lowest odi total new zealand 108. \n",
            "\n",
            "Summary: govt directs alok verma join work 1 day retirement\n",
            "Text:    weeks ex cbi director alok verma told department personnel training consider retired home ministry asked join work last day fixed tenure director thursday. ministry directed immediately join dg fire services post transferred removal cbi chief. \n",
            "\n",
            "Summary: called pm modi ir 10 times satisfy ego andhra cm\n",
            "Text:    andhra pradesh cm n chandrababu naidu said when met us president bill clinton addressed mr clinton ir . modi junior politics. . . i addressed sir 10 times. i this. . . to satisfy ego hope justice state added. \n",
            "\n",
            "Summary: cong wins ramgarh bypoll rajasthan takes total 100 seats\n",
            "Text:    congress candidate shafia zubair ramgarh assembly seat rajasthan defeating bjp sukhwant singh margin 12 228 votes bypoll. victory congress taken total 100 seats 200 member assembly. election ramgarh seat delayed due death sitting mla bsp candidate laxman singh. \n",
            "\n",
            "Summary: cousins fed human excreta friendship boys\n",
            "Text:    two minor cousins uttar pradesh gorakhpur allegedly repeatedly burnt tongs forced eat human excreta family friends two boys school. cousins revealed ordeal police child welfare committee brought back gorakhpur nepal fled escape torture. \n",
            "\n",
            "Summary: 81 yr old woman conducts physical training j khand schools\n",
            "Text:    isha ghosh 81 year old member bharat scouts guides imparting physical mental training schoolchildren jharkhand several decades. chaibasa based ghosh reportedly walks seven kilometres daily spends eight hours conducting physical training apart climbing yoga sessions. says one something society till one last breath. \n",
            "\n",
            "Summary: ram krishna smoke we ramdev sadhus kumbh\n",
            "Text:    urging saints seers kumbh mela quit smoking yoga guru ramdev said we follow ram krishna never smoked life we making take pledge quit tobacco collected chillum several sadhus. said deposit chillums display museum build. \n",
            "\n",
            "Summary: pharma exec gave doctor lap dance sell medicine us witness\n",
            "Text:    former stripper regional sales director pharmaceutical company sunrise lee gave doctor lap dance nightclub persuade prescribe addictive fentanyl spray 2012 company sales representative told us court. said saw lee sitting doctor lap kind bouncing around. lee accused bribing doctors. \n",
            "\n",
            "Summary: cried bidaai felt peer pressure isha ambani\n",
            "Text:    reliance industries chairman mukesh ambani daughter isha ambani got married last month said cried bidaai felt peer pressure everyone crying especially parents. i emotional everyone around would cry time added. it emotional affair everyone family said isha. \n",
            "\n",
            "Summary: louis vuitton owner stockpile 4 months wine spirits uk\n",
            "Text:    louis vuitton owner lvmh makes high end beverages like mo t chandon champagne hennessy cognac said stockpiling four months worth wine spirits uk preparation brexit. we ready worst case scenario difficulties deliveries french luxury giant said. uk scheduled leave eu march 29. \n",
            "\n",
            "Summary: karan johar tabu turn showstoppers opening night lfw\n",
            "Text:    filmmaker karan johar actress tabu turned showstoppers gaurav gupta opening night lakm fashion week summer resort 2019. johar wore red sequinned jacket black pants tabu walked ramp grey embellished gown. fashion show began january 29 continue till february 3. \n",
            "\n",
            "Summary: bail go jail pm modi takes jibe rahul\n",
            "Text:    jibe congress president rahul gandhi pm narendra modi wednesday said bail go jail. pm modi added he bail associates facing charges. . . i know convicted one day. pm claimed would waged war corruption common household. \n",
            "\n",
            "Summary: long tolerate congress leaders potshots k taka cm\n",
            "Text:    days threatened step post congress mlas continue crossing line karnataka chief minister hd kumaraswamy accused taking potshots asked how many days tolerate stuff kumaraswamy made statements congress mla demanded siddaramaiah made cm again said power ephemeral. \n",
            "\n",
            "Summary: odisha cm patnaik controls mining mafia union minister\n",
            "Text:    union minister dharmendra pradhan wednesday claimed illegal mining mafia odisha operates control cm naveen patnaik state congress chief niranjan patnaik. added the time come people odisha put full stop activities. . . the time come us ask explanation corrupt government. \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmM0BxDgYOoc"
      },
      "source": [
        "**Torch Req**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-pmlj-bYOoc"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU87EiEqYOoc"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9nNvklIYOod"
      },
      "source": [
        "def readLangs(text, summary):\n",
        "    \n",
        "    pairs = [[text[i],summary[i]] for i in range(len(text))]\n",
        "\n",
        "    input_lang = Lang(text)\n",
        "    output_lang = Lang(summary)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-PfCX-qYOod"
      },
      "source": [
        "def prepareData(lang1, lang2):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2)\n",
        "\n",
        "    print(f'Read {pairs} sentence pairs', end='\\n\\n')\n",
        "\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "\n",
        "    print(input_lang.name, input_lang.n_words, end='\\n\\n')\n",
        "    print(output_lang.name, output_lang.n_words, end='\\n\\n')\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap5M9WYtYOod",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1d751a3-a355-4d78-8023-b687ec7840f5"
      },
      "source": [
        "input_lang, output_lang, pairs = prepareData(x, y)\n",
        "\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0        saurav kant alumnus upgrad iiit b pg program m...\n",
            "1        kunal shah credit card bill payment platform c...\n",
            "2        new zealand defeated india 8 wickets fourth od...\n",
            "3        aegon life iterm insurance plan customers enjo...\n",
            "4        speaking sexual harassment allegations rajkuma...\n",
            "                               ...                        \n",
            "98396    crpf jawan tuesday axed death sharp edged weap...\n",
            "98397     uff yeh first song sonakshi sinha starrer upc...\n",
            "98398    according reports new version 1999 science fic...\n",
            "98399    new music video shows rapper snoop dogg aiming...\n",
            "98400    madhesi morcha alliance seven political partie...\n",
            "Name: text, Length: 98401, dtype: object 100136\n",
            "\n",
            "0        upgrad learner switches career ml al 90 salary...\n",
            "1         delhi techie wins free food swiggy one year cred\n",
            "2        new zealand end rohit sharma led india 12 matc...\n",
            "3        aegon life iterm insurance plan helps customer...\n",
            "4                 known hirani yrs metoo claims true sonam\n",
            "                               ...                        \n",
            "98396           crpf jawan axed death maoists chhattisgarh\n",
            "98397       first song sonakshi sinha noor titled uff yeh \n",
            "98398                   the matrix film get reboot reports\n",
            "98399    snoop dogg aims gun clown dressed trump new video\n",
            "98400    madhesi morcha withdraws support nepalese gove...\n",
            "Name: headlines, Length: 98401, dtype: object 35048\n",
            "\n",
            "['margin victory first ever test 1877 match played celebrate test cricket centenary 1977. australia beat england 45 runs first ever test also special match started march 12 england 100 years later margin. matches played melbourne. ', 'margin victory first ever centenary tests']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ays-jqBMDhhk"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTST4a8CYOoe"
      },
      "source": [
        "MAX_LENGTH = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBaEileeYOoe"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAfjBTvLYOoe"
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQheDzSXYOof"
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax( self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pnwgITqYOof"
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIDe9XZ2YOof"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]\n",
        "\n",
        "    else:\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2gXkPYgYOog"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return f'{m}m {s}s'\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return f'Time: {asMinutes(s)} (ETA: {asMinutes(rs)})'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-Uxp6YLYOog"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcWi8Dl0YOog"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    print(\"Training....\")\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0\n",
        "    plot_loss_total = 0\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    # encoder_optimizer = optim.AdamW(encoder.parameters())\n",
        "    # decoder_optimizer = optim.AdamW(decoder.parameters())\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        if iter% 1000 == 0:\n",
        "            print(iter,\"/\",n_iters + 1)\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print(f'{(timeSince(start, iter / n_iters)} (iter: {iter} percent: {iter / n_iters * 100}%%) %.4f' % print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwNFydmiYOog"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWrJlKfTYOoh"
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('Text:       ', pair[0])\n",
        "        print('Summary:    ', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('Prediction: ', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmmuQwHaYOoh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05303a9f-55f4-4598-9c25-403d914435bb"
      },
      "source": [
        "hidden_size = 200\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 50000, print_every=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training....\n",
            "1000 / 50001\n",
            "2m 11s (- 107m 29s) (1000 2%) 6.9665\n",
            "2000 / 50001\n",
            "4m 21s (- 104m 41s) (2000 4%) 7.2466\n",
            "3000 / 50001\n",
            "6m 33s (- 102m 46s) (3000 6%) 7.1989\n",
            "4000 / 50001\n",
            "8m 46s (- 100m 51s) (4000 8%) 7.1776\n",
            "5000 / 50001\n",
            "10m 58s (- 98m 45s) (5000 10%) 7.0914\n",
            "6000 / 50001\n",
            "13m 10s (- 96m 33s) (6000 12%) 7.0301\n",
            "7000 / 50001\n",
            "15m 21s (- 94m 18s) (7000 14%) 7.0375\n",
            "8000 / 50001\n",
            "17m 33s (- 92m 10s) (8000 16%) 7.0442\n",
            "9000 / 50001\n",
            "19m 45s (- 90m 2s) (9000 18%) 7.0591\n",
            "10000 / 50001\n",
            "21m 57s (- 87m 50s) (10000 20%) 7.0480\n",
            "11000 / 50001\n",
            "24m 8s (- 85m 36s) (11000 22%) 6.9976\n",
            "12000 / 50001\n",
            "26m 20s (- 83m 24s) (12000 24%) 6.9607\n",
            "13000 / 50001\n",
            "28m 30s (- 81m 9s) (13000 26%) 6.9743\n",
            "14000 / 50001\n",
            "30m 42s (- 78m 57s) (14000 28%) 7.0121\n",
            "15000 / 50001\n",
            "32m 53s (- 76m 44s) (15000 30%) 6.9018\n",
            "16000 / 50001\n",
            "35m 4s (- 74m 31s) (16000 32%) 6.9362\n",
            "17000 / 50001\n",
            "37m 15s (- 72m 20s) (17000 34%) 6.9019\n",
            "18000 / 50001\n",
            "39m 27s (- 70m 9s) (18000 36%) 6.9120\n",
            "19000 / 50001\n",
            "41m 38s (- 67m 56s) (19000 38%) 7.0318\n",
            "20000 / 50001\n",
            "43m 49s (- 65m 44s) (20000 40%) 7.0532\n",
            "21000 / 50001\n",
            "46m 1s (- 63m 33s) (21000 42%) 7.0343\n",
            "22000 / 50001\n",
            "48m 11s (- 61m 20s) (22000 44%) 6.8598\n",
            "23000 / 50001\n",
            "50m 22s (- 59m 8s) (23000 46%) 6.9747\n",
            "24000 / 50001\n",
            "52m 34s (- 56m 57s) (24000 48%) 7.0884\n",
            "25000 / 50001\n",
            "54m 46s (- 54m 46s) (25000 50%) 7.0124\n",
            "26000 / 50001\n",
            "56m 58s (- 52m 35s) (26000 52%) 6.9768\n",
            "27000 / 50001\n",
            "59m 9s (- 50m 23s) (27000 54%) 7.0039\n",
            "28000 / 50001\n",
            "61m 20s (- 48m 12s) (28000 56%) 6.9646\n",
            "29000 / 50001\n",
            "63m 32s (- 46m 1s) (29000 57%) 6.8896\n",
            "30000 / 50001\n",
            "65m 45s (- 43m 50s) (30000 60%) 6.9056\n",
            "31000 / 50001\n",
            "67m 57s (- 41m 39s) (31000 62%) 6.8830\n",
            "32000 / 50001\n",
            "70m 10s (- 39m 28s) (32000 64%) 6.9694\n",
            "33000 / 50001\n",
            "72m 22s (- 37m 17s) (33000 66%) 6.8368\n",
            "34000 / 50001\n",
            "74m 34s (- 35m 5s) (34000 68%) 6.9331\n",
            "35000 / 50001\n",
            "76m 46s (- 32m 54s) (35000 70%) 6.9080\n",
            "36000 / 50001\n",
            "78m 58s (- 30m 42s) (36000 72%) 6.8126\n",
            "37000 / 50001\n",
            "81m 10s (- 28m 31s) (37000 74%) 6.8278\n",
            "38000 / 50001\n",
            "83m 23s (- 26m 19s) (38000 76%) 6.8162\n",
            "39000 / 50001\n",
            "85m 35s (- 24m 8s) (39000 78%) 6.8370\n",
            "40000 / 50001\n",
            "87m 48s (- 21m 57s) (40000 80%) 6.7922\n",
            "41000 / 50001\n",
            "90m 1s (- 19m 45s) (41000 82%) 6.7349\n",
            "42000 / 50001\n",
            "92m 15s (- 17m 34s) (42000 84%) 6.7479\n",
            "43000 / 50001\n",
            "94m 27s (- 15m 22s) (43000 86%) 6.7057\n",
            "44000 / 50001\n",
            "96m 40s (- 13m 10s) (44000 88%) 6.7570\n",
            "45000 / 50001\n",
            "98m 52s (- 10m 59s) (45000 90%) 6.6364\n",
            "46000 / 50001\n",
            "101m 4s (- 8m 47s) (46000 92%) 6.6200\n",
            "47000 / 50001\n",
            "103m 16s (- 6m 35s) (47000 94%) 6.6291\n",
            "48000 / 50001\n",
            "105m 28s (- 4m 23s) (48000 96%) 6.6034\n",
            "49000 / 50001\n",
            "107m 40s (- 2m 11s) (49000 98%) 6.7064\n",
            "50000 / 50001\n",
            "109m 52s (- 0m 0s) (50000 100%) 6.4820\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHFfbfqqYOoh"
      },
      "source": [
        "torch.save(encoder1.state_dict(), './enc.w')\n",
        "torch.save(attn_decoder1.state_dict(), './att.w')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5HUdsm1YOoh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd4c89b6-ebf9-4738-9c78-b4054441d362"
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> us tuesday imposed fresh sanctions 13 chinese north korean organisations accusing supporting north korea nuclear programme trade commodities like coal helping evade nuclear restrictions .  comes us president donald trump declared north korea state sponsor terrorism .  notably north korea 90 trade china . n\n",
            "= us announces sanctions china n korea trade\n",
            "< us n n korea n n korea n korea <EOS>\n",
            "\n",
            "> us startup elysium space partnered elon muskled spacex launch ashes 300 people space .  spacecraft reservations cost 1 . 6 lakh per person travel around earth pass every location world .  following twoyear journey spacecraft reenter earth orbit burn reentry . \n",
            "= spacex send ashes 300 people space 1 . 6 lakh\n",
            "< us musk launches first first time <EOS>\n",
            "\n",
            "> cbi joint director rajiv singh heading investigations 2 . 1billion pnb fraud involving nirav modi mehul choksi prematurely repatriated home cadre tripura .  move comes agency plans file red corner notice nirav choksi .  three bureaucrats also repatriated upon request respective state governments . \n",
            "= officer probing nirav modi scam repatriated cbi\n",
            "< case cm accused 2 . 5 <EOS>\n",
            "\n",
            "> us president donald trump call buy housing 5 years ago proven right .  now time buy housing values fully recovered .  5 years remember told so trump tweeted 2012 .  notably house price index data collected us federal reserve shows consistent growth fiveyearrange confirming trump prediction . \n",
            "= trump 5yearold real estate prediction proves right\n",
            "< trump trump trump trump trump trump <EOS>\n",
            "\n",
            "> centre told supreme court taking help usbased national centre missing exploited children  curb child porn india .  private body acts resource centre information missing exploited children reportedly trying establish secure communication link cbi sharing details . \n",
            "= private us body helping india curb child porn centre sc\n",
            "< sc seeks plea aadhaar sc <EOS>\n",
            "\n",
            "> aap leader ashutosh monday asserted conclusion could drawn exit polls results recent mcd elections .  advised people patient wait till results announced april 26 .  notably exit polls predicted sweeping victory bjp party winning 202220 seats . \n",
            "= believe exit polls aap mcd polls\n",
            "< cong mp cm bjp cong mp <EOS>\n",
            "\n",
            "> goods services tax network  information technology backbone india new tax regime capable handling 1 . 2 lakh transactions every second amounting 320 crore transactions month .  network handle 60000 users time every second chairman gst network navin kumar said . \n",
            "= many transactions gst network handle\n",
            "< china may crore crore . crore <EOS>\n",
            "\n",
            "> finance minister arun jaitley sunday said congress president rahul gandhi idea single tax slab goods services tax  flawed .  a single slab gst function countries entire population similar higher level paying capacity jaitley added .  current gst structure five tax slabs . \n",
            "= rahul idea single gst slab flawed fm arun jaitley\n",
            "< cong pm rahul pm rahul pm <EOS>\n",
            "\n",
            "> series photos published spanish media monday terrorists linked 2017 attack spain barcelona seen preparing bombs smiling camera .  one men preparing explosives younes abouyaaqoub 22 drove van crowd people killing 13 people . \n",
            "= terrorist smiled prepared bombs 2017 barcelona attack report\n",
            "< world cup world cup <EOS>\n",
            "\n",
            "> talking garbage segregation goa cm manohar parrikar said puppies kittens dumped still alive garbage .  added 25 puppies 35 kittens rescued goa waste treatment plant garbage segregation .  parrikar said responding question assembly processing refusederived fuel collected plant . \n",
            "= puppies kittens dumped alive garbage goa cm\n",
            "< cong mp cm yogi bjp mp <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}